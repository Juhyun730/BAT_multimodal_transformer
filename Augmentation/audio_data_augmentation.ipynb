{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcdcc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "# reproducibility\n",
    "\n",
    "def all_seed(seed_num):\n",
    "    np.random.seed(seed_num)\n",
    "    rn.seed(seed_num)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    # tf.random.set_seed(seed_num)\n",
    "\n",
    "seed_num = 42\n",
    "all_seed(seed_num)\n",
    "\n",
    "a_filename = './wav/Sess01_script01_User001F_001.wav'\n",
    "samples, sample_rate = librosa.load(a_filename)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# plt.plot(np.linspace(0, sample_rate/len(samples), len(samples)), samples)\n",
    "librosa.display.waveshow(samples, sr=40000)\n",
    "\n",
    "plt.xlabel('time', fontsize = 14)\n",
    "plt.ylabel('amplitude', fontsize = 14)\n",
    "plt.title('001.wav | Length : ' + str(len(samples)))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "samples, sample_rate = librosa.load(a_filename)\n",
    "X = librosa.stft(samples)  # data -> short term FT\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.title('001.wav spectrogram | Length : ' + str(len(samples)))\n",
    "librosa.display.specshow(Xdb, sr = sample_rate, x_axis='time', y_axis='hz')   \n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def extract_features(sample):\n",
    "    \n",
    "    # MFCC\n",
    "    mfcc =librosa.feature.mfcc(y = sample, sr = sample_rate,n_mfcc=50)\n",
    "    padded_mfcc = pad2d(mfcc, 600) #padding\n",
    "    scaler = MinMaxScaler(feature_range=(0,1)) ## 각 칼럼 데이터 값을 0~1 범위로 변환\n",
    "\n",
    "    scaler.fit(padded_mfcc) ## 각 칼럼 데이터마다 변환할 함수 생성\n",
    "\n",
    "    scaled_padded_mfcc = scaler.transform(padded_mfcc) ## fit에서 만들어진 함수를 실제로 데이터에 적용\n",
    "\n",
    "    result = np.array([scaled_padded_mfcc])\n",
    "    return result\n",
    "pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(14) \n",
    "def noise(sample, rate):\n",
    "    noise_amp = rate*np.random.uniform()*np.amax(sample)\n",
    "    sample = sample + noise_amp*np.random.normal(size = sample.shape[0])\n",
    "    return sample\n",
    "\n",
    "# time stretching\n",
    "def stretch(sample, rate):\n",
    "    stretch_sample = librosa.effects.time_stretch(y=sample, rate=rate)\n",
    "    return stretch_sample\n",
    "\n",
    "\n",
    "# pitch 변환\n",
    "def pitch(sample, pitch_factor, sampling_rate=22050):\n",
    "    pitch_sample = librosa.effects.pitch_shift(y=sample, sr=sampling_rate, n_steps=pitch_factor)\n",
    "    return pitch_sample\n",
    "\n",
    "\n",
    "def get_features(path,num):\n",
    "\n",
    "    sample, sample_rate = librosa.load(path)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(sample)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    for i in range(num//2):\n",
    "        # sample with noise\n",
    "        rate = np.random.uniform(0,0.2)\n",
    "        noise_sample = noise(sample,rate)\n",
    "        res2 = extract_features(noise_sample)\n",
    "        result = np.vstack((result, res2)) \n",
    "    \n",
    "    for i in range(num//2):\n",
    "        # sample with stretching and pitching\n",
    "        rate = np.random.uniform(0.7, 0.9)\n",
    "        pitch_rate = np.random.uniform(0.7,0.9)\n",
    "        str_sample = stretch(sample,rate)\n",
    "        sample_stretch_pitch = pitch(str_sample,pitch_rate)\n",
    "        res3 = extract_features(sample_stretch_pitch)\n",
    "        result = np.vstack((result, res3)) \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3976772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"train.pkl\",\"rb\") as fr:\n",
    "    data = pickle.load(fr)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be2f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train, x_valid, y_train, y_valid = train_test_split(train[['Segment ID','temp+eda','text_tokenize','mfcc_scaled']], data['sentiment_x'], test_size=0.2, shuffle=True, random_state=4)\n",
    "x_train = data[['Segment ID','temp+eda','text_tokenize','mfcc_scaled']]\n",
    "y_train = data['sentiment_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888cd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d25728",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['sentiment_x']==0]),len(data[data['sentiment_x']==1]),len(data[data['sentiment_x']==2]),len(data[data['sentiment_x']==3]),len(data[data['sentiment_x']==4]),len(data[data['sentiment_x']==5]),len(data[data['sentiment_x']==6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba328fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yes0\n",
    "#no0\n",
    "tmp = pd.concat([x_train,y_train], axis=1)\n",
    "yes0 =tmp[tmp['sentiment_x']==0]\n",
    "yes1 =tmp[tmp['sentiment_x']==1]\n",
    "yes2 =tmp[tmp['sentiment_x']==2]\n",
    "yes3 =tmp[tmp['sentiment_x']==3]\n",
    "yes4 =tmp[tmp['sentiment_x']==4]\n",
    "yes5 =tmp[tmp['sentiment_x']==5]\n",
    "yes6 =tmp[tmp['sentiment_x']==6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69027de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes0 # augmentation X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98343f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0cb244",
   "metadata": {},
   "source": [
    "# yes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce066d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "labels = yes1['sentiment_x']\n",
    "x, y = [], []\n",
    "file_name = ['./wav/'+f+'.wav' for f in yes1['Segment ID']]\n",
    "NUM=6\n",
    "for f, label in tqdm(zip(file_name, labels)):\n",
    "    \n",
    "    feature = get_features(f, NUM)\n",
    "    #print(feature)\n",
    "    for fe in feature:\n",
    "        x.append(np.array(fe).transpose())\n",
    "\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f2fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = [i for i in yes1['Segment ID'] for s in range(NUM+1)]\n",
    "text = [i for i in yes1['text_tokenize'] for s in range(NUM+1)]\n",
    "bio = [i for i in yes1['temp+eda'] for s in range(NUM+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yes1df={'Segment ID': seg,'mfcc_scaled':x,'text_tokenize':text, 'temp+eda':bio,'sentiment_x':y}\n",
    "yes1df = pd.DataFrame(yes1df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes1df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('augmentedyes1.pkl','wb') as fr:\n",
    "    pickle.dump(yes1df, fr, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be9472",
   "metadata": {},
   "source": [
    "# yes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612652bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "labels = yes2['sentiment_x']\n",
    "x, y = [], []\n",
    "file_name = ['./wav/'+f+'.wav' for f in yes2['Segment ID']]\n",
    "NUM=44\n",
    "for f, label in tqdm(zip(file_name, labels)):\n",
    "    \n",
    "    feature = get_features(f, NUM)\n",
    "    #print(feature)\n",
    "    for fe in feature:\n",
    "        x.append(np.array(fe).transpose())\n",
    "\n",
    "        y.append(label)\n",
    "seg = [i for i in yes2['Segment ID'] for s in range(NUM+1)]\n",
    "text = [i for i in yes2['text_tokenize'] for s in range(NUM+1)]\n",
    "bio = [i for i in yes2['temp+eda'] for s in range(NUM+1)]\n",
    "\n",
    "\n",
    "yes2df={'Segment ID': seg,'mfcc_scaled':x,'text_tokenize':text, 'temp+eda':bio,'sentiment_x':y}\n",
    "yes2df = pd.DataFrame(yes2df)\n",
    "\n",
    "yes2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('augmentedyes2.pkl','wb') as fr:\n",
    "    pickle.dump(yes2df, fr, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b382fbf",
   "metadata": {},
   "source": [
    "# yes3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a50fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x), len(y), len(seg), len(text), len(bio))\n",
    "#yes5df={'Segment ID': seg,'mfcc_scaled':x,'text_tokenize':text, 'temp+eda':bio,'sentiment_x':y}\n",
    "len(yes3)*49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "labels = yes3['sentiment_x']\n",
    "x, y = [], []\n",
    "file_name = ['./wav/'+f+'.wav' for f in yes3['Segment ID']]\n",
    "NUM=49\n",
    "for f, label in tqdm(zip(file_name, labels)):\n",
    "    \n",
    "    feature = get_features(f, NUM)\n",
    "    #print(feature)\n",
    "    for fe in feature:\n",
    "        x.append(np.array(fe).transpose())\n",
    "        y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba95d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = [i for i in yes3['Segment ID'] for s in range(NUM)]\n",
    "text = [i for i in yes3['text_tokenize'] for s in range(NUM)]\n",
    "bio = [i for i in yes3['temp+eda'] for s in range(NUM)]\n",
    "\n",
    "\n",
    "yes3df={'Segment ID': seg,'mfcc_scaled':x,'text_tokenize':text, 'temp+eda':bio,'sentiment_x':y}\n",
    "yes3df = pd.DataFrame(yes3df)\n",
    "\n",
    "yes3df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('augmentedyes3.pkl','wb') as fr:\n",
    "    pickle.dump(yes3df, fr, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe890fe",
   "metadata": {},
   "source": [
    "# yes4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e96b8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "labels = yes4['sentiment_x']\n",
    "x, y = [], []\n",
    "file_name = ['./wav/'+f+'.wav' for f in yes4['Segment ID']]\n",
    "NUM=57\n",
    "for f, label in tqdm(zip(file_name, labels)):\n",
    "    \n",
    "    feature = get_features(f, NUM)\n",
    "    #print(feature)\n",
    "    for fe in feature:\n",
    "        x.append(np.array(fe).transpose())\n",
    "\n",
    "        y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = [i for i in yes4['Segment ID'] for s in range(NUM)]\n",
    "text = [i for i in yes4['text_tokenize'] for s in range(NUM)]\n",
    "bio = [i for i in yes4['temp+eda'] for s in range(NUM)]\n",
    "\n",
    "\n",
    "yes4df={'Segment ID': seg,'mfcc_scaled':x,'text_tokenize':text, 'temp+eda':bio,'sentiment_x':y}\n",
    "yes4df = pd.DataFrame(yes4df)\n",
    "\n",
    "yes4df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d1ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('augmentedyes4.pkl','wb') as fr:\n",
    "    pickle.dump(yes4df, fr, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3383e8",
   "metadata": {},
   "source": [
    "# yes5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "labels = yes5['sentiment_x']\n",
    "x, y = [], []\n",
    "file_name = ['./wav/'+f+'.wav' for f in yes5['Segment ID']]\n",
    "NUM=88\n",
    "for f, label in tqdm(zip(file_name, labels)):\n",
    "    \n",
    "    feature = get_features(f, NUM)\n",
    "    #print(feature)\n",
    "    for fe in feature:\n",
    "        x.append(np.array(fe).transpose())\n",
    "\n",
    "        y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045752d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = [i for i in yes5['Segment ID'] for s in range(NUM+1)]\n",
    "text = [i for i in yes5['text_tokenize'] for s in range(NUM+1)]\n",
    "bio = [i for i in yes5['temp+eda'] for s in range(NUM+1)]\n",
    "\n",
    "\n",
    "yes5df={'Segment ID': seg,'mfcc_scaled':x,'text_tokenize':text, 'temp+eda':bio,'sentiment_x':y}\n",
    "yes5df = pd.DataFrame(yes5df)\n",
    "\n",
    "yes5df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('augmentedyes5.pkl','wb') as fr:\n",
    "    pickle.dump(yes5df, fr, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85cdcf",
   "metadata": {},
   "source": [
    "# yes6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2595fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "labels = yes6['sentiment_x']\n",
    "x, y = [], []\n",
    "file_name = ['./wav/'+f+'.wav' for f in yes6['Segment ID']]\n",
    "NUM=202\n",
    "for f, label in tqdm(zip(file_name, labels)):\n",
    "    \n",
    "    feature = get_features(f, NUM)\n",
    "    #print(feature)\n",
    "    for fe in feature:\n",
    "        x.append(np.array(fe).transpose())\n",
    "\n",
    "        y.append(label)\n",
    "seg = [i for i in yes6['Segment ID'] for s in range(NUM+1)]\n",
    "text = [i for i in yes6['text_tokenize'] for s in range(NUM+1)]\n",
    "bio = [i for i in yes6['temp+eda'] for s in range(NUM+1)]\n",
    "\n",
    "\n",
    "yes6df={'Segment ID': seg,'mfcc_scaled':x,'text_tokenize':text, 'temp+eda':bio,'sentiment_x':y}\n",
    "yes6df = pd.DataFrame(yes6df)\n",
    "\n",
    "yes6df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('augmentedyes6.pkl','wb') as fr:\n",
    "    pickle.dump(yes6df, fr, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ce754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.concat((yes0,yes1df,yes2df,yes3df,yes4df,yes5df,yes6df),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b2e2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF['sentiment_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a138d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('augmented2.pkl','wb') as fr:\n",
    "    pickle.dump(DF, fr, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7da2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "with open('augmentedhalf1.pkl','wb') as fr:\n",
    "    pickle.dump(DF.iloc[:len(DF)//2], fr, pickle.HIGHEST_PROTOCOL)\n",
    "with open('augmentedhalf2.pkl','wb') as fr:\n",
    "    pickle.dump(DF.iloc[len(DF)//2:], fr, pickle.HIGHEST_PROTOCOL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0407",
   "language": "python",
   "name": "uajhmulmo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
