{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116fe2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64cf5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EDA_x_train.pkl', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "\n",
    "with open('EDA_y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open('EDA_x_valid.pkl', 'rb') as f:\n",
    "    x_valid = pickle.load(f)\n",
    "\n",
    "with open('EDA_y_valid.pkl', 'rb') as f:\n",
    "    y_valid = pickle.load(f)\n",
    "\n",
    "with open('EDA_x_test.pkl', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "\n",
    "with open('EDA_y_test.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a4f7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24500,) (1121,) (24500,) (1121,)\n",
      "(2567,) (1121,) (2567,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_valid.shape, y_train.shape, y_valid.shape)\n",
    "print(x_test.shape,y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee3ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):  #공통적인 트랜스포머 블럭\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(embedding_dim=embed_dim, num_heads=num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        #print('어텐션 후',attn_output.shape)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        #print('드롭아웃',attn_output.shape)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        #print('레이어놈',out1.shape)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        #print('ffn후',ffn_output.shape)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        print(\"트랜스포머\")\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "class MultiHeadAttention(tf.keras.layers.Layer): #공통적인 트랜스포머 멀티헤드어텐션\n",
    "    def __init__(self, embedding_dim, num_heads=4):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim # d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        logits = matmul_qk / tf.math.sqrt(depth)\n",
    "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        query = self.split_heads(query, batch_size)  \n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
    "        # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd270166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "236e70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eda_TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, embed_dimm):\n",
    "        super(eda_TokenAndPositionEmbedding, self).__init__()\n",
    "        self.temp_emb = tf.keras.layers.Embedding(input_dim=max_len, output_dim=embed_dim)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=max_len, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = 80\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.temp_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0665681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트랜스포머\n",
      "트랜스포머\n",
      "(None, 7)\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32 # Embedding size for each token\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "maxlen=50\n",
    "training=1\n",
    "\n",
    "eda_input = layers.Input(shape=(80,)) #\n",
    "eda_embedding_layer = eda_TokenAndPositionEmbedding(80, embed_dim)\n",
    "eda_embedding = eda_embedding_layer(eda_input)  #\n",
    "\n",
    "transformer_block = TransformerBlock(32, num_heads, ff_dim) \n",
    "\n",
    "output = transformer_block(eda_embedding)\n",
    "output = transformer_block(output)\n",
    "\n",
    "x = layers.GlobalAveragePooling1D()(output)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"sigmoid\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "outputs = layers.Dense(7, activation=\"softmax\")(x)  \n",
    "print(outputs.shape)\n",
    "\n",
    "model = keras.Model(inputs=eda_input, outputs=outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4b37ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "트랜스포머\n",
      "트랜스포머\n",
      "트랜스포머\n",
      "트랜스포머\n",
      "1529/1532 [============================>.] - ETA: 0s - loss: 1.9054 - accuracy: 0.2026트랜스포머\n",
      "트랜스포머\n",
      "1532/1532 [==============================] - 27s 16ms/step - loss: 1.9052 - accuracy: 0.2028 - val_loss: 1.8794 - val_accuracy: 0.0366\n",
      "Epoch 2/5\n",
      "1532/1532 [==============================] - 24s 16ms/step - loss: 1.7999 - accuracy: 0.2753 - val_loss: 1.9024 - val_accuracy: 0.0250\n",
      "Epoch 3/5\n",
      "1532/1532 [==============================] - 24s 16ms/step - loss: 1.7305 - accuracy: 0.3082 - val_loss: 1.9610 - val_accuracy: 0.0294\n",
      "Epoch 4/5\n",
      "1532/1532 [==============================] - 24s 16ms/step - loss: 1.6816 - accuracy: 0.3280 - val_loss: 1.8370 - val_accuracy: 0.0491\n",
      "Epoch 5/5\n",
      "1532/1532 [==============================] - 23s 15ms/step - loss: 1.6437 - accuracy: 0.3411 - val_loss: 1.9119 - val_accuracy: 0.0660\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [np.array(x_train.to_list())], y_train, batch_size=16, epochs=5, validation_data=([np.array(x_valid.to_list())], y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409b2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_np = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4538bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col = x_test\n",
    "list_col_array = np.array(list_col.tolist())\n",
    "new_df = pd.DataFrame(list_col_array, columns=[f'col{i+1}' for i in range(list_col_array.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6a6156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col71</th>\n",
       "      <th>col72</th>\n",
       "      <th>col73</th>\n",
       "      <th>col74</th>\n",
       "      <th>col75</th>\n",
       "      <th>col76</th>\n",
       "      <th>col77</th>\n",
       "      <th>col78</th>\n",
       "      <th>col79</th>\n",
       "      <th>col80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.239397</td>\n",
       "      <td>3.234272</td>\n",
       "      <td>3.229146</td>\n",
       "      <td>3.243241</td>\n",
       "      <td>3.245804</td>\n",
       "      <td>3.247085</td>\n",
       "      <td>3.238116</td>\n",
       "      <td>3.240678</td>\n",
       "      <td>3.239397</td>\n",
       "      <td>3.235553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.143951</td>\n",
       "      <td>4.138826</td>\n",
       "      <td>4.134982</td>\n",
       "      <td>4.131138</td>\n",
       "      <td>4.128576</td>\n",
       "      <td>4.128576</td>\n",
       "      <td>4.129857</td>\n",
       "      <td>4.132420</td>\n",
       "      <td>4.127295</td>\n",
       "      <td>4.119607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.453379</td>\n",
       "      <td>3.458504</td>\n",
       "      <td>3.450816</td>\n",
       "      <td>3.448254</td>\n",
       "      <td>3.443129</td>\n",
       "      <td>3.436722</td>\n",
       "      <td>3.435441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.079888</td>\n",
       "      <td>4.072201</td>\n",
       "      <td>4.045294</td>\n",
       "      <td>4.041451</td>\n",
       "      <td>4.023513</td>\n",
       "      <td>4.022232</td>\n",
       "      <td>4.014544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.438003</td>\n",
       "      <td>3.445691</td>\n",
       "      <td>3.480287</td>\n",
       "      <td>3.523852</td>\n",
       "      <td>3.548198</td>\n",
       "      <td>3.563574</td>\n",
       "      <td>3.575106</td>\n",
       "      <td>3.577668</td>\n",
       "      <td>3.582793</td>\n",
       "      <td>3.623796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>1.194537</td>\n",
       "      <td>1.171473</td>\n",
       "      <td>1.150971</td>\n",
       "      <td>1.129189</td>\n",
       "      <td>1.106125</td>\n",
       "      <td>1.093311</td>\n",
       "      <td>1.075373</td>\n",
       "      <td>1.056153</td>\n",
       "      <td>1.043339</td>\n",
       "      <td>1.053590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>0.929301</td>\n",
       "      <td>0.922894</td>\n",
       "      <td>0.917769</td>\n",
       "      <td>0.916488</td>\n",
       "      <td>0.912644</td>\n",
       "      <td>0.903674</td>\n",
       "      <td>0.903674</td>\n",
       "      <td>0.898549</td>\n",
       "      <td>0.892142</td>\n",
       "      <td>0.887017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>0.888298</td>\n",
       "      <td>0.880610</td>\n",
       "      <td>0.878048</td>\n",
       "      <td>0.875485</td>\n",
       "      <td>0.874204</td>\n",
       "      <td>0.867797</td>\n",
       "      <td>0.866516</td>\n",
       "      <td>0.867797</td>\n",
       "      <td>0.858828</td>\n",
       "      <td>0.857546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>0.831920</td>\n",
       "      <td>0.825513</td>\n",
       "      <td>0.821669</td>\n",
       "      <td>0.822950</td>\n",
       "      <td>0.819107</td>\n",
       "      <td>0.816544</td>\n",
       "      <td>0.813981</td>\n",
       "      <td>0.815262</td>\n",
       "      <td>0.806293</td>\n",
       "      <td>0.805012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>0.797324</td>\n",
       "      <td>0.794761</td>\n",
       "      <td>0.796043</td>\n",
       "      <td>0.794761</td>\n",
       "      <td>0.792199</td>\n",
       "      <td>0.792199</td>\n",
       "      <td>0.790917</td>\n",
       "      <td>0.784511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2567 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          col1      col2      col3      col4      col5      col6      col7  \\\n",
       "0     3.239397  3.234272  3.229146  3.243241  3.245804  3.247085  3.238116   \n",
       "1     4.143951  4.138826  4.134982  4.131138  4.128576  4.128576  4.129857   \n",
       "2     3.453379  3.458504  3.450816  3.448254  3.443129  3.436722  3.435441   \n",
       "3     4.079888  4.072201  4.045294  4.041451  4.023513  4.022232  4.014544   \n",
       "4     3.438003  3.445691  3.480287  3.523852  3.548198  3.563574  3.575106   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2562  1.194537  1.171473  1.150971  1.129189  1.106125  1.093311  1.075373   \n",
       "2563  0.929301  0.922894  0.917769  0.916488  0.912644  0.903674  0.903674   \n",
       "2564  0.888298  0.880610  0.878048  0.875485  0.874204  0.867797  0.866516   \n",
       "2565  0.831920  0.825513  0.821669  0.822950  0.819107  0.816544  0.813981   \n",
       "2566  0.797324  0.794761  0.796043  0.794761  0.792199  0.792199  0.790917   \n",
       "\n",
       "          col8      col9     col10  ...  col71  col72  col73  col74  col75  \\\n",
       "0     3.240678  3.239397  3.235553  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1     4.132420  4.127295  4.119607  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2     0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "3     0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4     3.577668  3.582793  3.623796  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
       "2562  1.056153  1.043339  1.053590  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2563  0.898549  0.892142  0.887017  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2564  0.867797  0.858828  0.857546  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2565  0.815262  0.806293  0.805012  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2566  0.784511  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      col76  col77  col78  col79  col80  \n",
       "0       0.0    0.0    0.0    0.0    0.0  \n",
       "1       0.0    0.0    0.0    0.0    0.0  \n",
       "2       0.0    0.0    0.0    0.0    0.0  \n",
       "3       0.0    0.0    0.0    0.0    0.0  \n",
       "4       0.0    0.0    0.0    0.0    0.0  \n",
       "...     ...    ...    ...    ...    ...  \n",
       "2562    0.0    0.0    0.0    0.0    0.0  \n",
       "2563    0.0    0.0    0.0    0.0    0.0  \n",
       "2564    0.0    0.0    0.0    0.0    0.0  \n",
       "2565    0.0    0.0    0.0    0.0    0.0  \n",
       "2566    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[2567 rows x 80 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3621ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_np = np.array(new_df)\n",
    "x_test_tensor = tf.convert_to_tensor(x_test_np)\n",
    "x_test_tensor = tf.cast(x_test_tensor, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a4e882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트랜스포머\n",
      "트랜스포머\n",
      "81/81 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "751aaac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=[]\n",
    "for i in y_pred:\n",
    "    yp.append(i.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459e623",
   "metadata": {},
   "source": [
    "## EDA 데이터 (train은 증강한거 test는 증강 안한거 8개 세션)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fcbc2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  11  196  239   72  236  205 1103]\n",
      " [   4   50   30    8   57   28  184]\n",
      " [   0    5    3    1    7    4    9]\n",
      " [   0    8    8    1    3    3   25]\n",
      " [   0    5    4    1    8    3   15]\n",
      " [   0    4    3    1    1    4    3]\n",
      " [   0    2    2    0    1    2    8]]\n",
      "{'0': {'precision': 0.7333333333333333, 'recall': 0.00533462657613967, 'f1-score': 0.01059220028887819, 'support': 2062}, '1': {'precision': 0.18518518518518517, 'recall': 0.13850415512465375, 'f1-score': 0.15847860538827258, 'support': 361}, '2': {'precision': 0.010380622837370242, 'recall': 0.10344827586206896, 'f1-score': 0.018867924528301883, 'support': 29}, '3': {'precision': 0.011904761904761904, 'recall': 0.020833333333333332, 'f1-score': 0.015151515151515154, 'support': 48}, '4': {'precision': 0.025559105431309903, 'recall': 0.2222222222222222, 'f1-score': 0.045845272206303724, 'support': 36}, '5': {'precision': 0.01606425702811245, 'recall': 0.25, 'f1-score': 0.03018867924528302, 'support': 16}, '6': {'precision': 0.005939123979213066, 'recall': 0.5333333333333333, 'f1-score': 0.011747430249632894, 'support': 15}, 'accuracy': 0.033112582781456956, 'macro avg': {'precision': 0.14119519852846943, 'recall': 0.18195370663596444, 'f1-score': 0.04155308957974106, 'support': 2567}, 'weighted avg': {'precision': 0.615942304085143, 'recall': 0.033112582781456956, 'f1-score': 0.032191661940211405, 'support': 2567}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test.to_list(), yp))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_test.to_list(), yp, output_dict=True, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7f1b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.615942304085143, 'recall': 0.033112582781456956, 'f1-score': 0.032191661940211405, 'support': 2567}\n"
     ]
    }
   ],
   "source": [
    "report = metrics.classification_report(y_test.to_list(), yp, output_dict=True, digits=5)\n",
    "print(report['weighted avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65dc87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
