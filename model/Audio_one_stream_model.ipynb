{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9f94ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:25:00.257127: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Bidirectional, MaxPool1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dec59a",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c18eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Segment ID</th>\n",
       "      <th>mfcc_scaled</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>temp+eda</th>\n",
       "      <th>sentiment_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sess13_script06_User026F_019</td>\n",
       "      <td>[[0.0, 0.9999999999999999, 0.9608148846764442,...</td>\n",
       "      <td>[331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sess13_script06_User026F_019</td>\n",
       "      <td>[[0.0, 0.8893497060147615, 0.9251501458319147,...</td>\n",
       "      <td>[331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sess13_script06_User026F_019</td>\n",
       "      <td>[[0.0, 0.9672434656487046, 0.9493295501081099,...</td>\n",
       "      <td>[331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sess13_script06_User026F_019</td>\n",
       "      <td>[[0.0, 0.8324701301043231, 0.8910219154763063,...</td>\n",
       "      <td>[331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sess13_script06_User026F_019</td>\n",
       "      <td>[[0.0, 0.8692361742952204, 0.8943141198396264,...</td>\n",
       "      <td>[331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24495</th>\n",
       "      <td>7379</td>\n",
       "      <td>Sess35_script04_User070F_008</td>\n",
       "      <td>[[0.032945521331930516, 0.40808203802457316, 0...</td>\n",
       "      <td>[42, 262, 1, 2859, 326, 32, 2859, 100, 344, 11...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24496</th>\n",
       "      <td>7381</td>\n",
       "      <td>Sess31_script06_User061M_026</td>\n",
       "      <td>[[0.0, 0.489686164522752, 0.8910410850529435, ...</td>\n",
       "      <td>[1819, 224, 248, 12, 1140, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24497</th>\n",
       "      <td>7383</td>\n",
       "      <td>Sess34_script02_User068M_020</td>\n",
       "      <td>[[0.0012534706618411162, 0.4571524437803839, 0...</td>\n",
       "      <td>[534, 3934, 3934, 46, 1377, 4, 1618, 0, 0, 0, ...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24498</th>\n",
       "      <td>7387</td>\n",
       "      <td>Sess27_script06_User054M_001</td>\n",
       "      <td>[[0.09887480369794877, 0.5645720231907226, 0.7...</td>\n",
       "      <td>[15, 87, 722, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24499</th>\n",
       "      <td>7392</td>\n",
       "      <td>Sess04_script04_User008F_028</td>\n",
       "      <td>[[0.0, 0.4902733839971465, 0.8978884530814059,...</td>\n",
       "      <td>[44, 11, 383, 1843, 18, 712, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                    Segment ID  \\\n",
       "0          0  Sess13_script06_User026F_019   \n",
       "1          1  Sess13_script06_User026F_019   \n",
       "2          2  Sess13_script06_User026F_019   \n",
       "3          3  Sess13_script06_User026F_019   \n",
       "4          4  Sess13_script06_User026F_019   \n",
       "...      ...                           ...   \n",
       "24495   7379  Sess35_script04_User070F_008   \n",
       "24496   7381  Sess31_script06_User061M_026   \n",
       "24497   7383  Sess34_script02_User068M_020   \n",
       "24498   7387  Sess27_script06_User054M_001   \n",
       "24499   7392  Sess04_script04_User008F_028   \n",
       "\n",
       "                                             mfcc_scaled  \\\n",
       "0      [[0.0, 0.9999999999999999, 0.9608148846764442,...   \n",
       "1      [[0.0, 0.8893497060147615, 0.9251501458319147,...   \n",
       "2      [[0.0, 0.9672434656487046, 0.9493295501081099,...   \n",
       "3      [[0.0, 0.8324701301043231, 0.8910219154763063,...   \n",
       "4      [[0.0, 0.8692361742952204, 0.8943141198396264,...   \n",
       "...                                                  ...   \n",
       "24495  [[0.032945521331930516, 0.40808203802457316, 0...   \n",
       "24496  [[0.0, 0.489686164522752, 0.8910410850529435, ...   \n",
       "24497  [[0.0012534706618411162, 0.4571524437803839, 0...   \n",
       "24498  [[0.09887480369794877, 0.5645720231907226, 0.7...   \n",
       "24499  [[0.0, 0.4902733839971465, 0.8978884530814059,...   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0      [331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...   \n",
       "1      [331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...   \n",
       "2      [331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...   \n",
       "3      [331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...   \n",
       "4      [331, 29, 9462, 54, 4, 132, 70, 49, 3392, 9463...   \n",
       "...                                                  ...   \n",
       "24495  [42, 262, 1, 2859, 326, 32, 2859, 100, 344, 11...   \n",
       "24496  [1819, 224, 248, 12, 1140, 0, 0, 0, 0, 0, 0, 0...   \n",
       "24497  [534, 3934, 3934, 46, 1377, 4, 1618, 0, 0, 0, ...   \n",
       "24498  [15, 87, 722, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "24499  [44, 11, 383, 1843, 18, 712, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                                temp+eda  sentiment_x  \n",
       "0      [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            6  \n",
       "1      [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            6  \n",
       "2      [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            6  \n",
       "3      [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            6  \n",
       "4      [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            6  \n",
       "...                                                  ...          ...  \n",
       "24495  [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            0  \n",
       "24496  [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            0  \n",
       "24497  [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            0  \n",
       "24498  [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            0  \n",
       "24499  [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....            0  \n",
       "\n",
       "[24500 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('audio_augmented_per3500.pkl',\"rb\") as fr: #train 로드\n",
    "    train = pickle.load(fr)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f303a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1830638/2951617071.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['mfcc_scaled'][i]=np.mean(train['mfcc_scaled'][i],axis=1).reshape(600,1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(train['mfcc_scaled'])):\n",
    "    train['mfcc_scaled'][i]=np.mean(train['mfcc_scaled'][i],axis=1).reshape(600,1) #음성 데이터는 각 시퀀스끼리 mean 연산 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6047c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('valid.pkl',\"rb\") as fr: #valid 로드\n",
    "    valid = pickle.load(fr)\n",
    "valid=valid.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad2d4338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1830638/3701760537.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid['mfcc_scaled'][i]=np.mean(valid['mfcc_scaled'][i],axis=1).reshape(600,1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(valid['mfcc_scaled'])):\n",
    "    valid['mfcc_scaled'][i]=np.mean(valid['mfcc_scaled'][i],axis=1).reshape(600,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c42fba2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('test.pkl',\"rb\") as fr: #test 데이터 로드\n",
    "    test = pickle.load(fr)\n",
    "test=test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4838f465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1830638/468462434.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['mfcc_scaled'][i]=np.mean(test['mfcc_scaled'][i],axis=1).reshape(600,1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(test['mfcc_scaled'])):\n",
    "    test['mfcc_scaled'][i]=np.mean(test['mfcc_scaled'][i],axis=1).reshape(600,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2081ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train['sentiment_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ad4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid=valid['sentiment_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c5352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test['sentiment_x']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b038397a",
   "metadata": {},
   "source": [
    "# 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40b91e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class a_TokenAndPositionEmbedding(layers.Layer):#오디오 임베딩\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super().__init__()\n",
    "        self.a1_emb = tf.keras.layers.Conv1D(filters=32, kernel_size=5,padding='valid', activation='relu') #conv1d 연산 2번 진행\n",
    "        self.a2_emb = tf.keras.layers.Conv1D(filters=32, kernel_size=5,padding='valid', activation='relu')\n",
    "        self.a3_emb = MaxPool1D(pool_size=(12),padding='same') #maxpooling 진행\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim) \n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = 50\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.a1_emb(tf.convert_to_tensor(x))\n",
    "        x = self.a2_emb(x)\n",
    "        x = self.a3_emb(x)\n",
    "        \n",
    "        return x + positions #포지셔널 임베딩과 음성 임베딩 값 더해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45f50c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TransformerBlock(layers.Layer):  #트랜스포머 블럭\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(embedding_dim=embed_dim, num_heads=num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c175e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer): #트랜스포머 멀티헤드어텐션\n",
    "    def __init__(self, embedding_dim, num_heads=4):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim \n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        logits = matmul_qk / tf.math.sqrt(depth)\n",
    "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        query = self.split_heads(query, batch_size)  \n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
    "        # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb994e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "maxlen=50\n",
    "training=1\n",
    "\n",
    "audio_input = layers.Input(shape=(600,1)) \n",
    "a_embedding_layer = a_TokenAndPositionEmbedding(50, 32) #오디오 임베딩\n",
    "audio_embedding = a_embedding_layer(audio_input)\n",
    "\n",
    "transformer_block = TransformerBlock(32, num_heads, ff_dim) #오디오 트랜스포머 블럭\n",
    "\n",
    "output = transformer_block(audio_embedding)\n",
    "\n",
    "x = layers.GlobalAveragePooling1D()(output)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"sigmoid\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "outputs = layers.Dense(7, activation=\"softmax\")(x)  \n",
    "\n",
    "model = keras.Model(inputs=audio_input, outputs=outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f771fd69",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "178ea5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1532/1532 [==============================] - 13s 7ms/step - loss: 1.7343 - accuracy: 0.2959 - val_loss: 0.6900 - val_accuracy: 0.8310\n",
      "Epoch 2/5\n",
      "1532/1532 [==============================] - 10s 6ms/step - loss: 1.5790 - accuracy: 0.3465 - val_loss: 0.7066 - val_accuracy: 0.8310\n",
      "Epoch 3/5\n",
      "1532/1532 [==============================] - 10s 6ms/step - loss: 1.5334 - accuracy: 0.3884 - val_loss: 0.7028 - val_accuracy: 0.8310\n",
      "Epoch 4/5\n",
      "1532/1532 [==============================] - 10s 6ms/step - loss: 1.3927 - accuracy: 0.4514 - val_loss: 0.7301 - val_accuracy: 0.8246\n",
      "Epoch 5/5\n",
      "1532/1532 [==============================] - 10s 6ms/step - loss: 1.2731 - accuracy: 0.4967 - val_loss: 0.6984 - val_accuracy: 0.8310\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [np.array(train['mfcc_scaled'].to_list())], y_train, batch_size=16, epochs=5, validation_data=([np.array(valid['mfcc_scaled'].to_list())], y_valid)\n",
    ") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4e35346",
   "metadata": {},
   "source": [
    "# 테스트 데이터셋으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47217632",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict([np.array(test['mfcc_scaled'].to_list())])\n",
    "yp=[]\n",
    "for i in y_pred:\n",
    "    yp.append(i.argmax())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08cb96d5",
   "metadata": {},
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8c09d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.6452463916397767, 'recall': 0.8032723022984029, 'f1-score': 0.7156394414946237, 'support': 2567}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kie/anaconda3/envs/yajhmulmo/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kie/anaconda3/envs/yajhmulmo/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kie/anaconda3/envs/yajhmulmo/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test.to_list(), yp, output_dict=True, digits=5)['weighted avg'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd465595",
   "metadata": {},
   "source": [
    "증강 전 데이터를 사용하면 오버피팅이 매우 크고, 모델이 중립 감정만 찍는 경향이 있음 \n",
    "\n",
    "- 증강을 통해 모든 감정에 대해 모델이 잘 식별할 수 있도록 학습을 하고, sklearn 의 metrics를 활용하여 모든 감정에 대해 f1score를 구할 수 있었음\n",
    "\n",
    "- test 데이터셋은 랜덤 8개의 세션으로 구성된 데이터 셋임\n",
    "- test 데이터셋의 감정 분포도 중립이 타 감정(ex: 행복)에 비해 매우 많으므로 macro score가 아닌, weigthed score로 평가 진행\n",
    "- 최종스코어는 아래와 같음\n",
    "- {'precision': 0.6452463916397767, 'recall': 0.8032723022984029, 'f1-score': 0.7156394414946237} 의 성능을 낼 수 있었음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yajhmulmo",
   "language": "python",
   "name": "yajhmulmo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
