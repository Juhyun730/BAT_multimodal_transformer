{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"126yRrxBFXVe1xYViHWtT4ojgIdqvDCje","authorship_tag":"ABX9TyM2KEY5cx2zUp7w8GR555ul"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow import nn\n","import pandas as pd\n","import numpy as np\n","import pickle"],"metadata":{"id":"yO5AMxfQfhnW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZGb_KJJDbwDy"},"outputs":[],"source":["#증강 작업을 진행한 데이터셋 불러오기\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_x_train.pkl', \"rb\") as f:\n","    x_train = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_y_train.pkl', \"rb\") as f:\n","    y_train = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_x_valid.pkl', \"rb\") as f:\n","    x_valid = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_y_valid.pkl', \"rb\") as f:\n","    y_valid = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_x_test.pkl', \"rb\") as f:\n","    x_test = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_y_test.pkl', \"rb\") as f:\n","    y_test = pickle.load(f)"]},{"cell_type":"code","source":["#text 데이터의 98% 이상이 모두 50토큰 이내 이므로 max_len=50, 제로 패딩 진행\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","x_train = pad_sequences(x_train, maxlen=50)\n","x_test = pad_sequences(x_test, maxlen=50)\n","x_valid = pad_sequences(x_valid, maxlen=50)"],"metadata":{"id":"CJNVWntKjFug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OealShJDjH2l","executionInfo":{"status":"ok","timestamp":1681913631156,"user_tz":-540,"elapsed":3,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"792601ff-e0b8-4410-dbcf-41963b9d505a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   0,    0,    0, ..., 2506, 3206,  447],\n","       [   0,    0,    0, ..., 4683,    6, 6358],\n","       [   0,    0,    0, ..., 1980,  733, 6359],\n","       ...,\n","       [   0,    0,    0, ...,    0,    8,  436],\n","       [   0,    0,    0, ..., 1139,    2,  307],\n","       [   0,    0,    0, ..., 1139,    2,  307]], dtype=int32)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["y_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9Z667VQjW4F","executionInfo":{"status":"ok","timestamp":1681913633019,"user_tz":-540,"elapsed":6,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"b5ebe7b5-dcde-48af-b248-8f8046f21a97"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1        1\n","2        0\n","3        0\n","4        4\n","5        0\n","        ..\n","29653    3\n","29654    3\n","29655    3\n","29656    1\n","29658    1\n","Name: sentiment, Length: 24500, dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["class TokenAndPositionEmbedding(layers.Layer):\n","    def __init__(self, maxlen,vocab_size, embed_dim):\n","        super().__init__()\n","        self.t_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim) #텍스트 임베딩\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","    def call(self, x):\n","        maxlen=50\n","        print(\"t\")\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\n","        positions = self.pos_emb(positions)\n","\n","        x = self.t_emb(x) #텍스트 임베딩\n","        return x + positions\n","class TransformerBlock(layers.Layer):  #공통적인 트랜스포머 블럭\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super().__init__()\n","        self.att = MultiHeadAttention(embedding_dim=embed_dim, num_heads=num_heads)\n","        self.ffn = keras.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs)\n","        #print('어텐션 후',attn_output.shape)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        #print('드롭아웃',attn_output.shape)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        #print('레이어놈',out1.shape)\n","        ffn_output = self.ffn(out1)\n","        #print('ffn후',ffn_output.shape)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        print(\"트랜스포머\")\n","        return self.layernorm2(out1 + ffn_output)"],"metadata":{"id":"JQN4Tc-MjX3r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(tf.keras.layers.Layer): #공통적인 트랜스포머 멀티헤드어텐션\n","    def __init__(self, embedding_dim, num_heads=4):\n","        super(MultiHeadAttention, self).__init__()\n","        self.embedding_dim = embedding_dim # d_model\n","        self.num_heads = num_heads\n","\n","        assert embedding_dim % self.num_heads == 0\n","\n","        self.projection_dim = embedding_dim // num_heads\n","        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n","        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n","        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n","        self.dense = tf.keras.layers.Dense(embedding_dim)\n","\n","    def scaled_dot_product_attention(self, query, key, value):\n","        matmul_qk = tf.matmul(query, key, transpose_b=True)\n","        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","        logits = matmul_qk / tf.math.sqrt(depth)\n","        attention_weights = tf.nn.softmax(logits, axis=-1)\n","        output = tf.matmul(attention_weights, value)\n","        return output, attention_weights\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, inputs):\n","        # x.shape = [batch_size, seq_len, embedding_dim]\n","        batch_size = tf.shape(inputs)[0]\n","\n","        # (batch_size, seq_len, embedding_dim)\n","        query = self.query_dense(inputs)\n","        key = self.key_dense(inputs)\n","        value = self.value_dense(inputs)\n","\n","        # (batch_size, num_heads, seq_len, projection_dim)\n","        query = self.split_heads(query, batch_size)  \n","        key = self.split_heads(key, batch_size)\n","        value = self.split_heads(value, batch_size)\n","\n","        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n","        # (batch_size, seq_len, num_heads, projection_dim)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n","\n","        # (batch_size, seq_len, embedding_dim)\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n","        outputs = self.dense(concat_attention)\n","        return outputs"],"metadata":{"id":"deEEvHWNjiCY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import backend as K\n","def recall(y_target, y_pred):\n","    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n","    # round : 반올림한다\n","    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n","    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n","\n","    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n","    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n","\n","    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n","    count_true_positive_false_negative = K.sum(y_target_yn)\n","\n","    # Recall =  (True Positive) / (True Positive + False Negative)\n","    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n","    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n","\n","    # return a single tensor value\n","    return recall\n","\n","\n","def precision(y_target, y_pred):\n","    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n","    # round : 반올림한다\n","    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n","    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n","\n","    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n","    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n","\n","    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n","    count_true_positive_false_positive = K.sum(y_pred_yn)\n","\n","    # Precision = (True Positive) / (True Positive + False Positive)\n","    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n","    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n","\n","    # return a single tensor value\n","    return precision\n","\n","\n","def f1score(y_target, y_pred):\n","    _recall = recall(y_target, y_pred)\n","    _precision = precision(y_target, y_pred)\n","    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n","    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n","    \n","    # return a single tensor value\n","    return _f1score"],"metadata":{"id":"h7tUK-FijlWr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embed_dim = 32 # Embedding size for each token\n","num_heads = 4  # Number of attention heads\n","ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n","maxlen=50\n","training=1\n","\n","text_input = layers.Input(shape=(50,)) #\n","t_embedding_layer = TokenAndPositionEmbedding(50,12440+1, embed_dim)\n","text_embedding = t_embedding_layer(text_input)  ########## \n","\n","transformer_block = TransformerBlock(32, num_heads, ff_dim) \n","\n","output = transformer_block(text_embedding)\n","output = transformer_block(output) #트랜스포머 블럭 1층 추가\n","\n","x = layers.GlobalAveragePooling1D()(output)\n","x = layers.Dropout(0.1)(x)\n","x = layers.Dense(20, activation=\"sigmoid\")(x) #활성함수로 시그모이드 함수 사용\n","x = layers.Dropout(0.1)(x)\n","\n","outputs = layers.Dense(7, activation=\"softmax\")(x)  #클래시파이어(분류기)\n","print(outputs.shape)\n","\n","model = keras.Model(inputs=text_input, outputs=outputs)\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfzRpCLpjpq5","executionInfo":{"status":"ok","timestamp":1681913646420,"user_tz":-540,"elapsed":821,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"b3076e47-2b61-4171-c46b-53330fd4b299"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["t\n","트랜스포머\n","트랜스포머\n","(None, 7)\n"]}]},{"cell_type":"code","source":["history = model.fit(\n","    x_train, y_train, batch_size=16, epochs=5, validation_data=(x_valid, y_valid)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681913854173,"user_tz":-540,"elapsed":205044,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"310e0931-1e33-4992-8162-d03c652a2e2d","id":"96u_0LUZH5Q1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","t\n","트랜스포머\n","트랜스포머\n","t\n","트랜스포머\n","트랜스포머\n","1531/1532 [============================>.] - ETA: 0s - loss: 0.7076 - accuracy: 0.7808t\n","트랜스포머\n","트랜스포머\n","1532/1532 [==============================] - 40s 24ms/step - loss: 0.7075 - accuracy: 0.7809 - val_loss: 0.7366 - val_accuracy: 0.7629\n","Epoch 2/5\n","1532/1532 [==============================] - 32s 21ms/step - loss: 0.2271 - accuracy: 0.9393 - val_loss: 0.9222 - val_accuracy: 0.7068\n","Epoch 3/5\n","1532/1532 [==============================] - 25s 16ms/step - loss: 0.1360 - accuracy: 0.9657 - val_loss: 1.0702 - val_accuracy: 0.6780\n","Epoch 4/5\n","1532/1532 [==============================] - 25s 16ms/step - loss: 0.0979 - accuracy: 0.9737 - val_loss: 1.1221 - val_accuracy: 0.7142\n","Epoch 5/5\n","1532/1532 [==============================] - 25s 16ms/step - loss: 0.0771 - accuracy: 0.9798 - val_loss: 0.9539 - val_accuracy: 0.7326\n"]}]},{"cell_type":"code","source":["x_test_np = np.array(x_test)\n","\n","list_col = x_test\n","list_col_array = np.array(list_col.tolist())\n","new_df = pd.DataFrame(list_col_array, columns=[f'col{i+1}' for i in range(list_col_array.shape[1])])"],"metadata":{"id":"UsFGZ74AX0xn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_df #test에 사용할 데이터프레임 생성"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"5nAJrRXuYHzr","executionInfo":{"status":"ok","timestamp":1681913859860,"user_tz":-540,"elapsed":6,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"febaf429-5f1d-4365-e15a-0eb2c187daa0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      col1  col2  col3  col4  col5  col6  col7  col8  col9  col10  ...  col41  \\\n","0        0     0     0     0     0     0     0     0     0      0  ...     20   \n","1        0     0     0     0     0     0     0     0     0      0  ...      0   \n","2        0     0     0     0     0     0     0     0     0      0  ...      0   \n","3        0     0     0     0     0     0     0     0     0      0  ...      0   \n","4        0     0     0     0     0     0     0     0     0      0  ...   2857   \n","...    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...    ...   \n","2609     0     0     0     0     0     0     0     0     0      0  ...     59   \n","2610     0     0     0     0     0     0     0     0     0      0  ...      0   \n","2611     0     0     0     0     0     0     0     0     0      0  ...     22   \n","2612     0     0     0     0     0     0     0     0     0      0  ...    763   \n","2613     0     0     0     0     0     0     0     0     0      0  ...      0   \n","\n","      col42  col43  col44  col45  col46  col47  col48  col49  col50  \n","0       508   1900     28     17     38   1900     58     69   2018  \n","1         0      0      0      9    632    564     58    126   5849  \n","2         0      0      0      0     20      4   2771      5   1996  \n","3         0      0      0      0      0      0    250    613     50  \n","4       148      4    871    303     77    296   1213     29   1327  \n","...     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n","2609     75    143  12438     29    751    746     29    751     44  \n","2610      0      0      7    572    333      7   4603    494    466  \n","2611   2453    246     75     22     29   2453     29   1999    495  \n","2612     22   2453     26   2432    189     36      2    231     44  \n","2613     94     22    986     13  12440     54    226   2600    317  \n","\n","[2614 rows x 50 columns]"],"text/html":["\n","  <div id=\"df-2627d2e2-dd33-465e-a826-a782051acc0c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>col1</th>\n","      <th>col2</th>\n","      <th>col3</th>\n","      <th>col4</th>\n","      <th>col5</th>\n","      <th>col6</th>\n","      <th>col7</th>\n","      <th>col8</th>\n","      <th>col9</th>\n","      <th>col10</th>\n","      <th>...</th>\n","      <th>col41</th>\n","      <th>col42</th>\n","      <th>col43</th>\n","      <th>col44</th>\n","      <th>col45</th>\n","      <th>col46</th>\n","      <th>col47</th>\n","      <th>col48</th>\n","      <th>col49</th>\n","      <th>col50</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>20</td>\n","      <td>508</td>\n","      <td>1900</td>\n","      <td>28</td>\n","      <td>17</td>\n","      <td>38</td>\n","      <td>1900</td>\n","      <td>58</td>\n","      <td>69</td>\n","      <td>2018</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>632</td>\n","      <td>564</td>\n","      <td>58</td>\n","      <td>126</td>\n","      <td>5849</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>4</td>\n","      <td>2771</td>\n","      <td>5</td>\n","      <td>1996</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>250</td>\n","      <td>613</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>2857</td>\n","      <td>148</td>\n","      <td>4</td>\n","      <td>871</td>\n","      <td>303</td>\n","      <td>77</td>\n","      <td>296</td>\n","      <td>1213</td>\n","      <td>29</td>\n","      <td>1327</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2609</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>59</td>\n","      <td>75</td>\n","      <td>143</td>\n","      <td>12438</td>\n","      <td>29</td>\n","      <td>751</td>\n","      <td>746</td>\n","      <td>29</td>\n","      <td>751</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>2610</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>572</td>\n","      <td>333</td>\n","      <td>7</td>\n","      <td>4603</td>\n","      <td>494</td>\n","      <td>466</td>\n","    </tr>\n","    <tr>\n","      <th>2611</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>22</td>\n","      <td>2453</td>\n","      <td>246</td>\n","      <td>75</td>\n","      <td>22</td>\n","      <td>29</td>\n","      <td>2453</td>\n","      <td>29</td>\n","      <td>1999</td>\n","      <td>495</td>\n","    </tr>\n","    <tr>\n","      <th>2612</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>763</td>\n","      <td>22</td>\n","      <td>2453</td>\n","      <td>26</td>\n","      <td>2432</td>\n","      <td>189</td>\n","      <td>36</td>\n","      <td>2</td>\n","      <td>231</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>2613</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>94</td>\n","      <td>22</td>\n","      <td>986</td>\n","      <td>13</td>\n","      <td>12440</td>\n","      <td>54</td>\n","      <td>226</td>\n","      <td>2600</td>\n","      <td>317</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2614 rows × 50 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2627d2e2-dd33-465e-a826-a782051acc0c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2627d2e2-dd33-465e-a826-a782051acc0c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2627d2e2-dd33-465e-a826-a782051acc0c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["x_test_np = np.array(new_df)\n","x_test_tensor = tf.convert_to_tensor(x_test_np)\n","x_test_tensor = tf.cast(x_test_tensor, tf.int64) #텐서로 변환 작업 진행"],"metadata":{"id":"UrcbzHEEYI7p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(x_test_tensor)\n","\n","yp=[]\n","for i in y_pred:\n","    yp.append(i.argmax())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rtZfw9xMYK9x","executionInfo":{"status":"ok","timestamp":1681913869863,"user_tz":-540,"elapsed":2146,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"a2b67405-ebe7-4250-f286-f324ac2a13fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["t\n","트랜스포머\n","트랜스포머\n","82/82 [==============================] - 1s 8ms/step\n"]}]},{"cell_type":"code","source":["from sklearn import metrics\n","\n","# Print the precision and recall, among other metrics\n","print(\"accuracy: \",metrics.classification_report(y_test.to_list(), yp, output_dict=True, digits=3)['accuracy'])\n","print(\"weighted avg: \",metrics.classification_report(y_test.to_list(), yp, output_dict=True, digits=3)['weighted avg'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68jvTVHzYNl2","executionInfo":{"status":"ok","timestamp":1681913918776,"user_tz":-540,"elapsed":304,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"0a8e6491-3eb1-4d4a-e7d4-c3342be7a36d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy:  0.6966335118592196\n","weighted avg:  {'precision': 0.701616330759148, 'recall': 0.6966335118592196, 'f1-score': 0.6977080718299516, 'support': 2614}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IRKeQavCaZ54"},"execution_count":null,"outputs":[]}]}