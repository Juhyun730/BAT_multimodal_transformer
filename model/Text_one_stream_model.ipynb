{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"126yRrxBFXVe1xYViHWtT4ojgIdqvDCje","authorship_tag":"ABX9TyOafk5RnerrVlyJ1IpAGszB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow import nn\n","import pandas as pd\n","import numpy as np\n","import pickle"],"metadata":{"id":"yO5AMxfQfhnW","executionInfo":{"status":"ok","timestamp":1681396637634,"user_tz":-540,"elapsed":839,"user":{"displayName":"강효은","userId":"09017213458312197996"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ZGb_KJJDbwDy","executionInfo":{"status":"ok","timestamp":1681396708392,"user_tz":-540,"elapsed":2847,"user":{"displayName":"강효은","userId":"09017213458312197996"}}},"outputs":[],"source":["with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_x_train.pkl', \"rb\") as f:\n","    x_train = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_y_train.pkl', \"rb\") as f:\n","    y_train = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_x_valid.pkl', \"rb\") as f:\n","    x_valid = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_y_valid.pkl', \"rb\") as f:\n","    y_valid = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_x_test.pkl', \"rb\") as f:\n","    x_test = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/kcc_휴먼이해논문공모전/Text_y_test.pkl', \"rb\") as f:\n","    y_test = pickle.load(f)"]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","y_valid = to_categorical(y_valid)\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"metadata":{"id":"_yFt-tiFdC_6","executionInfo":{"status":"ok","timestamp":1681396722023,"user_tz":-540,"elapsed":310,"user":{"displayName":"강효은","userId":"09017213458312197996"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","x_train = pad_sequences(x_train, maxlen=50)\n","x_test = pad_sequences(x_test, maxlen=50)\n","x_valid = pad_sequences(x_valid, maxlen=50)"],"metadata":{"id":"CJNVWntKjFug","executionInfo":{"status":"ok","timestamp":1681396723785,"user_tz":-540,"elapsed":2,"user":{"displayName":"강효은","userId":"09017213458312197996"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["x_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OealShJDjH2l","executionInfo":{"status":"ok","timestamp":1681396725611,"user_tz":-540,"elapsed":3,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"f18e34cb-cee4-4710-ae48-89af26c67873"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   0,    0,    0, ..., 2506, 3206,  447],\n","       [   0,    0,    0, ..., 4683,    6, 6358],\n","       [   0,    0,    0, ..., 1980,  733, 6359],\n","       ...,\n","       [   0,    0,    0, ...,    0,    8,  436],\n","       [   0,    0,    0, ..., 1139,    2,  307],\n","       [   0,    0,    0, ..., 1139,    2,  307]], dtype=int32)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["y_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9Z667VQjW4F","executionInfo":{"status":"ok","timestamp":1681396727924,"user_tz":-540,"elapsed":7,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"016c3bba-0c71-4068-c873-126cc0e6bdd8"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 1., 0., ..., 0., 0., 0.],\n","       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["class TokenAndPositionEmbedding(layers.Layer):\n","    def __init__(self, maxlen,vocab_size, embed_dim):\n","        super().__init__()\n","        self.t_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim) #텍스트 임베딩\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","    def call(self, x):\n","        maxlen=50\n","        print(\"t\")\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\n","        positions = self.pos_emb(positions)\n","\n","        x = self.t_emb(x) #텍스트 임베딩\n","        return x + positions\n","class TransformerBlock(layers.Layer):  #공통적인 트랜스포머 블럭\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super().__init__()\n","        self.att = MultiHeadAttention(embedding_dim=embed_dim, num_heads=num_heads)\n","        self.ffn = keras.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs)\n","        #print('어텐션 후',attn_output.shape)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        #print('드롭아웃',attn_output.shape)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        #print('레이어놈',out1.shape)\n","        ffn_output = self.ffn(out1)\n","        #print('ffn후',ffn_output.shape)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        print(\"트랜스포머\")\n","        return self.layernorm2(out1 + ffn_output)"],"metadata":{"id":"JQN4Tc-MjX3r","executionInfo":{"status":"ok","timestamp":1681396742187,"user_tz":-540,"elapsed":3,"user":{"displayName":"강효은","userId":"09017213458312197996"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(tf.keras.layers.Layer): #공통적인 트랜스포머 멀티헤드어텐션\n","    def __init__(self, embedding_dim, num_heads=4):\n","        super(MultiHeadAttention, self).__init__()\n","        self.embedding_dim = embedding_dim # d_model\n","        self.num_heads = num_heads\n","\n","        assert embedding_dim % self.num_heads == 0\n","\n","        self.projection_dim = embedding_dim // num_heads\n","        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n","        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n","        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n","        self.dense = tf.keras.layers.Dense(embedding_dim)\n","\n","    def scaled_dot_product_attention(self, query, key, value):\n","        matmul_qk = tf.matmul(query, key, transpose_b=True)\n","        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","        logits = matmul_qk / tf.math.sqrt(depth)\n","        attention_weights = tf.nn.softmax(logits, axis=-1)\n","        output = tf.matmul(attention_weights, value)\n","        return output, attention_weights\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, inputs):\n","        # x.shape = [batch_size, seq_len, embedding_dim]\n","        batch_size = tf.shape(inputs)[0]\n","\n","        # (batch_size, seq_len, embedding_dim)\n","        query = self.query_dense(inputs)\n","        key = self.key_dense(inputs)\n","        value = self.value_dense(inputs)\n","\n","        # (batch_size, num_heads, seq_len, projection_dim)\n","        query = self.split_heads(query, batch_size)  \n","        key = self.split_heads(key, batch_size)\n","        value = self.split_heads(value, batch_size)\n","\n","        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n","        # (batch_size, seq_len, num_heads, projection_dim)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n","\n","        # (batch_size, seq_len, embedding_dim)\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n","        outputs = self.dense(concat_attention)\n","        return outputs"],"metadata":{"id":"deEEvHWNjiCY","executionInfo":{"status":"ok","timestamp":1681396744472,"user_tz":-540,"elapsed":3,"user":{"displayName":"강효은","userId":"09017213458312197996"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import backend as K\n","def recall(y_target, y_pred):\n","    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n","    # round : 반올림한다\n","    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n","    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n","\n","    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n","    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n","\n","    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n","    count_true_positive_false_negative = K.sum(y_target_yn)\n","\n","    # Recall =  (True Positive) / (True Positive + False Negative)\n","    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n","    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n","\n","    # return a single tensor value\n","    return recall\n","\n","\n","def precision(y_target, y_pred):\n","    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n","    # round : 반올림한다\n","    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n","    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n","\n","    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n","    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n","\n","    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n","    count_true_positive_false_positive = K.sum(y_pred_yn)\n","\n","    # Precision = (True Positive) / (True Positive + False Positive)\n","    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n","    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n","\n","    # return a single tensor value\n","    return precision\n","\n","\n","def f1score(y_target, y_pred):\n","    _recall = recall(y_target, y_pred)\n","    _precision = precision(y_target, y_pred)\n","    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n","    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n","    \n","    # return a single tensor value\n","    return _f1score"],"metadata":{"id":"h7tUK-FijlWr","executionInfo":{"status":"ok","timestamp":1681396744472,"user_tz":-540,"elapsed":2,"user":{"displayName":"강효은","userId":"09017213458312197996"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["embed_dim = 32 # Embedding size for each token\n","num_heads = 4  # Number of attention heads\n","ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n","maxlen=50\n","training=1\n","\n","text_input = layers.Input(shape=(50,)) #\n","t_embedding_layer = TokenAndPositionEmbedding(50,12440+1, embed_dim)\n","text_embedding = t_embedding_layer(text_input)  ########## \n","\n","transformer_block = TransformerBlock(32, num_heads, ff_dim) #일단은 블럭 하나만(추후 블럭 여러개 쌓아서 실험도 해보기!)\n","\n","output = transformer_block(text_embedding)\n","output = transformer_block(output) #트랜스포머 블럭 1층 추가\n","\n","x = layers.GlobalAveragePooling1D()(output)\n","x = layers.Dropout(0.1)(x)\n","x = layers.Dense(20, activation=\"relu\")(x)\n","x = layers.Dropout(0.1)(x)\n","\n","outputs = layers.Dense(7, activation=\"softmax\")(x)  #클래시파이어(분류기)\n","print(outputs.shape)\n","\n","model = keras.Model(inputs=text_input, outputs=outputs)\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy', precision, recall, f1score])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfzRpCLpjpq5","executionInfo":{"status":"ok","timestamp":1681396748117,"user_tz":-540,"elapsed":1801,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"25d637e4-7d08-4a21-bf76-175ebac4378d"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["t\n","트랜스포머\n","트랜스포머\n","(None, 7)\n"]}]},{"cell_type":"code","source":["history = model.fit(\n","    x_train, y_train, batch_size=16, epochs=5, validation_data=(x_valid, y_valid)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDxCBuF4DomW","executionInfo":{"status":"ok","timestamp":1681229470843,"user_tz":-540,"elapsed":331339,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"7294ba88-1420-49b2-c621-f57fa693d49b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","t\n","트랜스포머\n","트랜스포머\n","t\n","트랜스포머\n","트랜스포머\n","1531/1532 [============================>.] - ETA: 0s - loss: 0.7216 - accuracy: 0.7353 - precision: 0.7986 - recall: 0.6501 - f1score: 0.6991t\n","트랜스포머\n","트랜스포머\n","1532/1532 [==============================] - 61s 34ms/step - loss: 0.7217 - accuracy: 0.7353 - precision: 0.7986 - recall: 0.6501 - f1score: 0.6991 - val_loss: 0.7557 - val_accuracy: 0.7592 - val_precision: 0.7708 - val_recall: 0.7451 - val_f1score: 0.7574\n","Epoch 2/5\n","1532/1532 [==============================] - 61s 40ms/step - loss: 0.2119 - accuracy: 0.9358 - precision: 0.9444 - recall: 0.9258 - f1score: 0.9346 - val_loss: 0.8742 - val_accuracy: 0.7422 - val_precision: 0.7472 - val_recall: 0.7326 - val_f1score: 0.7397\n","Epoch 3/5\n","1532/1532 [==============================] - 57s 37ms/step - loss: 0.1208 - accuracy: 0.9638 - precision: 0.9680 - recall: 0.9604 - f1score: 0.9640 - val_loss: 1.0019 - val_accuracy: 0.7445 - val_precision: 0.7480 - val_recall: 0.7400 - val_f1score: 0.7439\n","Epoch 4/5\n","1532/1532 [==============================] - 53s 34ms/step - loss: 0.0857 - accuracy: 0.9755 - precision: 0.9788 - recall: 0.9721 - f1score: 0.9753 - val_loss: 1.2701 - val_accuracy: 0.7097 - val_precision: 0.7144 - val_recall: 0.7047 - val_f1score: 0.7093\n","Epoch 5/5\n","1532/1532 [==============================] - 58s 38ms/step - loss: 0.0660 - accuracy: 0.9796 - precision: 0.9828 - recall: 0.9776 - f1score: 0.9801 - val_loss: 1.3370 - val_accuracy: 0.7518 - val_precision: 0.7541 - val_recall: 0.7488 - val_f1score: 0.7513\n"]}]},{"cell_type":"code","source":["_loss, _acc, _precision, _recall, _f1score = model.evaluate(x_test, y_test, batch_size=16, verbose=1)\n","print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _precision, _recall, _f1score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681229478909,"user_tz":-540,"elapsed":2876,"user":{"displayName":"강효은","userId":"09017213458312197996"}},"outputId":"e97993dd-0c3d-47f9-cff2-91a479bc29f5","id":"WczB7oYQDu1l"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["164/164 [==============================] - 3s 16ms/step - loss: 1.5037 - accuracy: 0.7028 - precision: 0.7019 - recall: 0.6983 - f1score: 0.7000\n","loss: 1.504, accuracy: 0.703, precision: 0.702, recall: 0.698, f1score: 0.700\n"]}]}]}